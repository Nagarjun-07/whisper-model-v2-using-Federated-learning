# ğŸ§ EchoNet: Federated Speech Evaluation Platform

A Federated Learning-based project that trains and evaluates **speech-to-text models** across decentralized clients. It computes **Loss**, **WER (Word Error Rate)**, and **BLEU score** per client and visualizes performance over multiple training rounds.

---

## ğŸš€ Features

- ğŸ“¡ Federated training across multiple clients
- ğŸ™ï¸ Evaluation on real speech-to-text data
- ğŸ“‰ Metric computation per client:
  - Loss
  - Word Error Rate (WER)
  - BLEU Score
- ğŸ“Š Graphical visualization of performance metrics across training rounds
- âš¡ Optimized for GPU acceleration

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ main.py              # Training + evaluation script
â”œâ”€â”€ plots.ipynb          # Graphs and metrics visualizations
â”œâ”€â”€ README.md            # You're here!
```

## Clone the repository

Copy

- git clone https://github.com/your-username/EchoNet.git
- Install dependencies

python main.py
Visualize results Open plots.ipynb in Jupyter to view performance graphs.

ğŸ“Š Sample Graphs
Graphs generated during training:

ğŸ“ˆ Average WER vs Rounds

ğŸ“ˆ Average BLEU vs Rounds

ğŸ“ˆ Per-Client Loss

You can find graphs and visuals under the plots.ipynb notebook or assets/ folder if generated.

ğŸ§  Technologies Used
Python

PyTorch

Transformers (HuggingFace)

Federated Learning

Matplotlib & Seaborn for visualizations

ğŸ“œ Dataset
The dataset is split across 10 clients to simulate decentralized learning.

Each client holds a unique subset of the speech-to-text data for federated evaluation.

ğŸ§‘â€ğŸ’» Author
Nagarjun H
ğŸ“« nagarjunh77@gmail.com
ğŸŒ GitHub: Nagarjun-07
